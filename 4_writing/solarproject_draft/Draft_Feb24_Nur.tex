%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Author template for Management Science (mnsc) for articles with e-companion (EC)
%% Mirko Janc, Ph.D., INFORMS, mirko.janc@informs.org
%% ver. 0.95, December 2010
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\documentclass[mnsc,blindrev]{informs3} % current default for manuscript submission
%\documentclass[mnsc,nonblindrev]{informs3}
\documentclass[msom,blindrev]{informs3}
\OneAndAHalfSpacedXI % current default line spacing
%%\OneAndAHalfSpacedXII
%%\DoubleSpacedXII
%\DoubleSpacedXI

% If hyperref is used, dvi-to-ps driver of choice must be declared as
%   an additional option to the \documentstyle. For example
%\documentclass[dvips,mnsc]{informs3}      % if dvips is used
%\documentclass[dvipsone,mnsc]{informs3}   % if dvipsone is used, etc.

% Private macros here (check that there is no clash with the style)
\usepackage{graphicx}

% Natbib setup for author-year style
\usepackage{natbib}
 \bibpunct[, ]{(}{)}{,}{a}{}{,}%
 \def\bibfont{\small}%
 \def\bibsep{\smallskipamount}%
 \def\bibhang{24pt}%
 \def\newblock{\ }%
 \def\BIBand{and}%

\usepackage{booktabs}

%\usepackage{csquotes}
\usepackage[UKenglish,USenglish]{babel}
%%package to comment a whole block
\usepackage{verbatim}
%% Setup of theorem styles. Outcomment only one.
%% Preferred default is the first option.
\TheoremsNumberedThrough     % Preferred (Theorem 1, Lemma 1, Theorem 2)
%\TheoremsNumberedByChapter  % (Theorem 1.1, Lema 1.1, Theorem 1.2)
\ECRepeatTheorems

%% Setup of the equation numbering system. Outcomment only one.
%% Preferred default is the first option.
\EquationsNumberedThrough    % Default: (1), (2), ...
%\EquationsNumberedBySection % (1.1), (1.2), ...

% For new submissions, leave this number blank.
% For revisions, input the manuscript number assigned by the on-line
% system along with a suffix ".Rx" where x is the revision number.
\MANUSCRIPTNO{}

%%%%%%%%%%%%%%%%
\begin{document}
%%%%%%%%%%%%%%%%

% Outcomment only when entries are known. Otherwise leave as is and
%   default values will be used.
%\setcounter{page}{1}
%\VOLUME{00}%
%\NO{0}%
%\MONTH{Xxxxx}% (month or a similar seasonal id)
%\YEAR{0000}% e.g., 2005
%\FIRSTPAGE{000}%
%\LASTPAGE{000}%
%\SHORTYEAR{00}% shortened year (two-digit)
%\ISSUE{0000} %
%\LONGFIRSTPAGE{0001} %
%\DOI{10.1287/xxxx.0000.0000}%

% Author's names for the running heads
% Sample depending on the number of authors;
% \RUNAUTHOR{Jones}
% \RUNAUTHOR{Jones and Wilson}
% \RUNAUTHOR{Jones, Miller, and Wilson}
% \RUNAUTHOR{Jones et al.} % for four or more authors
% Enter authors following the given pattern:
%\RUNAUTHOR{}

% Title or shortened title suitable for running heads. Sample:
% \RUNTITLE{Bundling Information Goods of Decreasing Value}
% Enter the (shortened) title:
\RUNTITLE{Do Noisy Customer Reviews Discourage Online Platform Sellers? Empirical and Text Analysis of a Solar Marketplace}
%INhibitator, Impede, Hinder, Inpe
% Full title. Sample:
% \TITLE{Bundling Information Goods of Decreasing Value}
% Enter the full title:
\TITLE{Do Noisy Customer Reviews Discourage Online Platform Sellers? Empirical and Text Analysis of a Solar Marketplace}
% Hinder - Noisy Customer Reviews in an Online Solar Marketplace: Discouragement to Platform Sellers?

% Block of authors and their affiliations starts here:
% NOTE: Authors with same affiliation, if the order of authors allows,
%   should be entered in ONE field, separated by a comma.
%   \EMAIL field can be repeated if more than one author
\ARTICLEAUTHORS{%
\AUTHOR{Snidely Slippery}
\AFF{Department of Bread Spread Engineering, Dairy University, Cowtown, IL 60208, \EMAIL{slippery@dairy.edu}} %, \URL{}}
\AUTHOR{Marg Arinella}
\AFF{Institute for Food Adulteration, University of Food Plains, Food Plains, MN 55599, \EMAIL{m.arinella@adult.ufp.edu}}
% Enter all authors
} % end of the block

\ABSTRACT{%
This paper
% Enter your abstract
}%

% Sample
%\KEYWORDS{deterministic inventory theory; infinite linear programming duality;
%  existence of optimal policies; semi-Markov decision process; cyclic schedule}

% Fill in data. If unknown, outcomment the field
\KEYWORDS{marketplace, reviews} \HISTORY{Update: November, 2019}

\maketitle
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Samples of sectioning (and labeling) in MNSC
% NOTE: (1) \section and \subsection do NOT end with a period
%       (2) \subsubsection and lower need end punctuation
%       (3) capitalization is as shown (title style).
%
%\section{Introduction.}\label{intro} %%1.
%\subsection{Duality and the Classical EOQ Problem.}\label{class-EOQ} %% 1.1.
%\subsection{Outline.}\label{outline1} %% 1.2.
%\subsubsection{Cyclic Schedules for the General Deterministic SMDP.}
%  \label{cyclic-schedules} %% 1.2.1
%\section{Problem Description.}\label{problemdescription} %% 2.

% Text of your paper here

\section{Introduction}

Solar energy is booming in the world. It is one of the fastest growing energy generation technology with a dazzling 34\% growth worldwide in 2017 \citep{iea2018snapshot}. An important driver of this growth is increasing solar panel installations by electricity end-users. More and more, electricity end-users have been generating their own power with solar panels, reducing their reliance on electric utility companies. This type of solar generation skyrocketed in the last decade. For example, in the U.S., residential solar capacity increased by a factor of XY from 2012 to 2019 (US EIA XYZ). The annual residential solar panel installations are forecasted to grow 25\% per year for the U.S \citep{weaver_2019,seia} with an even larger surge in the U.S after the passing of California Solar mandate \citep{gtmsolar2018}.


There is an increasing trend of installing rooftop panels through online marketplaces. Consumer interest doubled in 11 states between 2017 to 2018, according to an analysis of website traffic \citep{energysageintel19}.
An online solar marketplace is an innovative business model that eases the rooftop solar panel adoption process for electricity end-users. It essentially serves as an intermediary which connects buyers and installers of panels, making the process more transparent \citep{dorsey2019access}.

In building an online marketplace, online reviews are considered as an essential functionality. In the literature, there are studies that investigate how the average customer \emph{ratings} impact a single firm's sales. The consensus is that the average customer ratings can have significant impact on sales, especially for products and services that entail searching and experiencing attributes \citep{zimmermann2018decomposing}. In this paper, our primary goal is to empirically study the impact of \emph{dispersion} of customer reviews on the performance metric of the platform, which is a composite of \emph{many} firms. To the best of our knowledge, there is no prior work that has studied this topic.

Customer ratings are generally measured on a five-point scale. In this paper, we consider customer \emph{reviews} that include both customer ratings and the review text made by verified buyers. Thus, our analysis employs recent text mining techniques as well as traditional statistical tools.


Our paper is also related to papers that investigates the effect of ratings on a single firm's performance metrics. In that stream, there is no consensus about the ultimate impact of dispersion of ratings on the firm's performance metric. Studies have demonstrated positive impacts \citep{chintagunta2010effects,chevalier2006effect,dellarocas2007exploring}, insignificant impact \citep{duan2008online}, and negative impacts in some instances \citep{wang2015user}.

In the literature, there are papers that show the positive impact of reviews on sales. There are also other papers that demonstrate  (AVERAGE LIT (Literature considered average effect)).\\




Different from these papers, we took a perspective of the marketplace operator. The marketplace perspective is an important one, especially from the marketplace providers' perspectives. Many new businesses are running a marketplace business model, and have designed the customer ratings functionality an essential part of the platform experience (CITE SOMETHING). In our work, we use the total number of successful proposals on a relevant local market to gauge the health of the marketplace. Total number of success proposals as a performance metric is consistent with common business practices in the investment circle \citep{boris_2018,galston_2017} as it is tied to a marketplace business's valuation. \\

Our objective is to understand the impact of review dispersion on the activity level of each participating supplier on the platform, which has not been studied before. Our study provides insights into the operation of a marketplace and ties reviews to


----[OLD VERSION]

Solar cells, also called photovoltaic cells, convert sunlight directly into electricity without carbon emissions. Today, electricity from solar cells has become competitive in many regions and photovoltaic systems are being deployed at large scales to help power the electric grid \citep{nrel.gov}.

Solar energy is blooming in the US and the world. It is one of the fastest growing energy generating technology with a dazzling 34\% growth worldwide in 2017 \citep{iea2018snapshot}. Just 6\% of American household have already installed solar panels at home with another 46\% say they have given serious thought to adding solar panels at their home in the past year (CITE kennedy thigpen 2019).Solar PV capacity increased by an annual rate of 50\%  in decade and residential solar is forecasted to grow 25\% per year \citep{weaver_2019,seia}; with an even larger upside in the U.S after the passing of California Solar mandate \citep{gtmsolar2018}. \\
Online marketplaces is an innovative business model that has shown to ease the rooftop solar panel adoption process. It serves as an intermediary which connects buyers and made the whole process more transparent \citep{dorsey2019access}. There is an increasing trend of installing rooftop panels through online market places. Consumer interest doubled in 11 states between 2017 to 2018, according to an analysis of website traffic \citep{energysageintel19}.  \\
In building an online marketplace, online reviews is considered an essential functionality. Studies have shown that reviews have significant impact on customers'  decision making process, especially for products and services that entail searching and experiencing attributes \citep{zimmermann2018decomposing}.  \\
In the literature, there are papers that show the positive impact of reviews on sales. There are also other papers that demonstrate  (AVERAGE LIT (Literature considered average effect)).\\
In this paper, different from this literature, our primary goal is to study the impact of dispersion of ratings on the  performance metric of the platform, which is a composite of many firms. To the best of our knowledge, there is no prior work that has studied this.

Our paper is also related to papers that investigates the effect of ratings on a single firm's performance metrics. In that stream, there is no consensus about the ultimate impact of dispersion of ratings on the firm's performance metric. Studies have demonstrated positive impacts \citep{chintagunta2010effects,chevalier2006effect,dellarocas2007exploring}, insignificant impact \citep{duan2008online}, and negative impacts in some instances \citep{wang2015user}.

Different from these papers, we took a perspective of the marketplace operator. The marketplace perspective is an important one, especially from the marketplace providers' perspectives. Many new businesses are running a marketplace business model, and have designed the customer ratings functionality an essential part of the platform experience (CITE SOMETHING). In our work, we use the total number of successful proposals on a relevant local market to gauge the health of the marketplace. Total number of success proposals as a performance metric is consistent with common business practices in the investment circle \citep{boris_2018,galston_2017} as it is tied to a marketplace business's valuation. \\

Our objective is to understand the impact of review dispersion on the activity level of each participating supplier on the platform, which has not been studied before. Our study provides insights into the operation of a marketplace and ties reviews to



\subsection{How Reviews Dispersion Impacts Activity Intensity(Literature Review) }
 In this section we describe several mechanisms by which reviews dispersion may impact installers activity intensity on a platform. \\
 Previous studies have established the important of performance feedback on worker productivity. In a hospital setting \cite{song2017closing} found a positive impact from public performance feedback to low-performing physicians. In a restaurant setting, coworker performances influence waiters own `up-selling' behavior, a reflection of efforts, in an non-linear, inverse U-shape fashion. \\
The concept of \textbf{ratings dispersion} has been explored in marketing literature. For example, \cite{luo2013impact} examined the brand ratings dispersion and its impact on firm values. In the economics literature, \cite{marinovic2015credibility} modeled the phenomenon of performance feedback signal with a noise in a principal-agent model and illustrated feedback noise has potential of inducing agents efforts. Overall, the impact of feedbacks dispersion is less explored in an operations setting. \\
The impact of high ratings could be two-folded. On the one hand, high variations could be an indicator that the ratings scheme is functioning as it is designed - it rewards good installer and records the bad deeds of the bad ones. It could encourage installers to pursue more leads in order to get a chance to be evaluated.
On the other hand, a high ratings variation could also be taken as a sign of picky customers on the market. Installers fear of establishing bad permanent reputation will be more cautious when getting into a market of potentially picky customers. \\
In this study, we make use of the detailed installer level activities data. We explore not only the impact of ratings, but more importantly, the nuanced impact of the ratings dispersion and reviews variation.

\subsection{Overview}

We first quantify the impact of dispersion with the activity intensity on an individual installer level; we then elevate our analysis to the platform level by connecting the impact of dispersion on local market level total transactions in relation to the dispersion in reviews.


\section{Data and Setting}

We analyze the interplay between customer reviews and firm activities (and outcomes) in an online marketplace for electricity end-users' solar panel installations. To do so, we collaborated with an online solar marketplace company, and obtained the full record of customer reviews and installer proposal activities on a monthly level from 2013 to 2018 in the marketplace. This data set is proprietary and it is the primary source of our analysis. We also complement the marketplace data with Tracking The Sun (TTS) data set from the Lawrence Berkeley National Laboratory. TTS is a comprehensive and publicly available data set on U.S. solar panel installations. Below, we provide details about our data and the setting of the online solar marketplace we study.


%We use a compilation of proprietary and publicly available data about residential solar markets. The focus of the study is about the actions and outcomes of an online marketplace for residential solar installations. We obtained, via collaboration with the marketplace company, the full record of customer reviews and installer actions on a monthly level from 2013 to 2018. We complement the marketplace data with Tracking The Sun (TTS) data set from Lawrence Berkeley National Laboratory. TTS aggregates data from more than 60 state and utility incentive programs. The full TTS data set covers more than 80\% of the U.S. PV
%market, making it the most comprehensive extant U.S. PV data set. It contains installation level information such as installer name, unit size and price which allow us to construct a big picture of solar installation activities that are happening on and off the marketplace.

\subsection{Online Solar Marketplace}

The solar marketplace (MKT) we study is an independent shopping website for electricity end-users (i.e., homeowners) who are interested in installing solar panels.  The marketplace operates in 33 states of the U.S., and allows solar panel installers to maintain a profile, receive information on and connect with potential customers in their service areas.

The marketplace operates as follows. First, each customer visits the marketplace website and enters her information, such as the location of her property. Each installer provides service in a particular region. If the customer's location falls into an installer's service area, the marketplace informs the installer about the customer's arrival along with her information. Next, every informed installer decides whether to make a proposal to the customer. After the customer observes installer proposals, there are two possible outcomes: Either the customer agrees to work with an installer, i.e., there is a successful \emph{match}, or the customer gives up the process, i.e., there is no matching. If the customer ends up working with the installer, she can leave a review that contains text and a rating ranging from 1 to 5 stars. The marketplace verifies customers who leave reviews. Hence, reviews are considered as authentic and not manipulated. Figure \ref{reviews_example} provides an example of how customer reviews are displayed on the marketplace.


\begin{figure}
	\centering
	\includegraphics[width=0.81\linewidth]{reviews_example.png}
	\caption{A sample customer review on the marketplace.}
	\label{reviews_example}
\end{figure}

Note that the key decision of each installer in the marketplace is whether to make a proposal for each potential customer.
 In this context, we study how the dispersion of customer reviews impact the (i) \emph{intensity of installer activity}, which is measured by how many proposals an installer makes per month, and (ii) number of matches, which is an important performance metric for the marketplace.

To answer these questions, we obtained rich panel data from the solar marketplace that contain all of its vetted installers across the U.S., installers' monthly activities and all customer reviews (text content and ratings) from the beginning of the marketplace (January of 2013), up to April 2018. Specifically, in our data set, we have observations about 416 installers about their monthly activities, i.e., the number of proposals made and the number of proposals won by each installer in every month, and 3607 pieces of customer reviews each with a rating, text content, time stamp, and the installer name with which the review is associated. Features of this data set are summarized in Table \ref{brief_data_desc}. We also collected the location information of each installer from their profiles, as illustrated in Figure \ref{fig:nationalinstallers}.

% Please add the following required packages to your document preamble:
% \usepackage{booktabs}
\begin{table}[]
\centering
\begin{tabular}{@{}ll@{}}
\toprule
           & Description           \\ \midrule
Installers & 416 Unique Installers \\
Ratings and reviews & 3607 pieces of review records with the rating, text content,timestamp \\
Time span  & from 2013 to 2018     \\
Monthly Records & 6522 pieces \\
Supplementary & Tracking the Sun data \\
\bottomrule
\end{tabular}
\caption{Main Data Source}
\label{brief_data_desc}
\end{table}






\begin{figure}
	\centering
	\includegraphics[width=1.1\linewidth]{national_installers.png}
	\caption{Installers in our data set}
	\label{fig:nationalinstallers}
\end{figure}

It is perhaps worth mentioning that based on our conversions with the online marketplace, the marketplace actively reaches out to solar installers to recruit them to join to platform and help them set up their profile. So, unlike starting a physical business, installers' fixed cost of entry to the marketplace is negligibly small (if not zero). This is indeed the case in many different platforms \citep{haddad2015consumer}. In light of this, in this study, we do not study the entry of installers to the marketplace. Rather, we focus on installers' activity levels after they establish their profiles on the marketplace.


%Lastly, we don't observe quitting the platform the same way as physical store closes off. We simply observe inactive profiles. Thus we do not explicitly investigate the exit behavior.





\subsection{Defining Local Market}
\label{defining_local_market}


Solar installation is a combination of product and service. As part of service, installers typically visit the customer site multiple times. Thus, each installer only operates  within a certain geographical area. This means that installers compete ``locally.'' That is, they only compete with installers that are relatively nearby. To capture this practical element, we identify what is called \emph{local markets} within the marketplace so that only installers in the same local market compete with each other.

To geographically segment the marketplace into local markets, we divide installers into multiple \emph{clusters} and treat each cluster as a separate local market. Boundaries of local markets cannot be simply defined by state, county, or congressional district borders because it is common for installers to cross these artificial borders to serve customers. Instead, we use installer locations and the state-of-the-art advanced clustering algorithm called OPTICS (short for \textit{Ordering Points To Identify the Clustering Structure}) to identify local markets.

The OPTICS routine is an unsupervised machine learning algorithm that identifies density-based clusters in spatial data. It is considered to be an extension of various commonly-used advanced clustering algorithms, such as the DBSCAN \citep{kanagala2016comparative}. Among others, an important advantage of the OPTICS algorithm is that it does not require setting the number of clusters before running the algorithm as in $k$-means clustering; rather, it identifies the optimal number of clusters using the data. Because of these advantages, it has been applied in various contexts, ranging from political science \citep{davidson2019neighborhood} to geography \citep{teimouri2016method}.

%data mining \citep{breunig2000fast},

In light of these, we create the geographic division of local markets with the following steps. First, we collected the 5-digit zipcode of
every installer in the marketplace. Figure \ref{fig:nationalinstallers} displays the location of every installer in our data set. We then converted each zipcode  to the representative coordinates based on the data provided by the \citet{us_census_bureau_2019}. This transformation is necessary to run the OPTICS algorithm on the location data. \textbf{Is the previous sentence true?} The OPTICS algorithm uses the maximum distance between two samples in a cluster as an input variable. Based on our conversations with the marketplace, we learned that the vast majority of customers get a quote from an installer within 100 miles of their property. We used 90 miles as the maximum distance input parameter to balance between having enough clusters to make use of the inherent variations and making sure that each cluster captures the local market condition. Based on this, the OPTICS algorithm generated 36 clusters.\footnote{We also checked the robustness of our results by taking the maximum distance parameter as 100 miles in the OPTICS algorithm. Our insights remain to be valid in that alternative formulation.} Each of these clusters geographically defines a local market boundary. Figure \ref{fig:markets} illustrates the centroid of each of these 36 clusters, which represents the centroid of each local market. Hereafter, for brevity, we refer to local markets simply as ``\emph{markets}.''



%\paragraph{OPTICS}  The OPTICS algorithm, short for \textit{Ordering Points To Identify the Clustering Structure}, is what we use to cluster installers' coordinates. The OPTICS routine is completed with the following parameter considerations:  \\
%\textbf{min samples: }
%The number of samples in a neighborhood for a point to be considered as a core point.  We use 2 as the default value.
%\textbf{metric}: haversine distance. Although not ideal, it better reflected the distance between two Latitude/Longitude points and is still fast enough in the clustering algorithm.  \textbf{max eps:} The maximum distance between two samples for one to be considered as in the neighborhood of the other. According to the survey that the marketplace conducted, 90.6 percent of customers get a quote from an installer within 100 miles of their property ( 81.7 percent from 50 miles). \citep{marsh_2019} We used 90 as the parameter to balance between having enough clusters to  make use of the inherent variations and make sure each cluster captured the local market condition. We use this cluster to define our market boundary geographically. Figure \ref{fig:markets} illustrates the centroid of each of these 36 clusters, which represents the centroid of each local market. Hereafter, for brevity, we refer to local markets simply as ``\emph{markets}.''



%(PROVIDE A PICTURE TO ILLUSTRATE THE CALINSKI-HARABASZ CURVE VS PARAMETER , refer to figure \ref{optics_parameter_gridsearch} and Calinski-Harabasz criteria : \citep{calinski1974dendrite}.





\begin{figure}
	\centering
	\includegraphics[width=1\linewidth]{histogram_ind_max_reviews_ct.png}
	\caption{Reviews Histogram by Installer}
	\label{histogram_ind_max_reviews_ct}
\end{figure}

\input{summarystats_top10states.tex}



\begin{figure}
	\centering
	\includegraphics[width=1\linewidth]{markets.jpg}
	\caption{Local Market Centroids}
	\label{fig:markets}
\end{figure}

\subsection{Measuring the Dispersion in Customer Reviews} \label{subsection_measure_dispersion}

In our analysis, a key explanatory variable is the dispersion in reviews, which can be measured with numeric ratings (from 1 to 5 stars) or the text content. Below, we first describe how we measure the dispersion of reviews based on ratings. We then explain the innovative word embedding model we use to measure the dispersion of reviews based on the text data. Our base empirical analysis uses the rating-based dispersion as a variable. We then check the robustness of our results by adding the text-based review dispersion as a separate variable in our analysis.

\subsubsection{Measuring Rating-Based Dispersion} \label{Subsec: Define Ent}
We measure the rating-based dispersion by calculating the \emph{entropy} of ratings. In information theory, the entropy is a common way to measure  the uncertainty in a random variable's possible realizations. In our setting, because the marketplace has a 5-star rating system, the entropy of ratings is
\begin{equation}\label{def: entropy}
H(R)=-\sum_{i=1}^{5} \text{Prob}(\text{Rating}=i) \ln(1/\text{Prob}(\text{Rating}=i)).
\end{equation}
For example, for a set of 5 reviews each with 4 stars (out of 5 stars), the entropy of ratings $\{4,4,4,4,4\}$ is zero. Alternatively, for a set of 5 reviews with ratings $\{3,5,3,5,4\}$, the entropy of ratings is 1.0549. Although both sets have the same average rating of 4, the latter set of ratings provides more information with a higher dispersion, hence has a higher entropy.


In light of this, we create three variables that measure the rating entropy in different dimensions for each month $t$. First variable is $\text{Entropy\_Self}_{i,t}$ that represents the entropy of each installer $i$'s own reviews. This is calculated on the set of reviews that are associated with installer $i$ up to (\textbf{and including?}) month $t$. Recalling that market boundaries are defined as in Section \ref{defining_local_market}, the second variable $\text{Entropy\_Others}_{i,t}$ that is the rating entropy of all other installers in installer $i$'s market, up to month $t$. In one of our extension sections, we will also consider the rating entropy on the market level. Thus, our third variable is $\text{Entropy\_Mkt}_{m,t}$ that represents the entropy of all ratings in the local market $m$, up to that month $t$.  Again, the market is defined as in Section \ref{defining_local_market}.

\textbf{Explain why we did not use standard deviation /variance to measure dispersion.}\\

\textbf{Please include the correlation between variance and average of reviews here.}\\

\subsubsection{Measuring Text-Based Dispersion via the Language Model BERT} \label{Subsec: Define Txt Ent}

In our analysis, we leverage the rich information in text reviews. To do so, we use the state-of-the-art word embedding model called BERT (short for \textit{Bidirectional Encoder Representations from Transformers}). BERT was developed by Google, and published in 2018 \citep{devlin2018bert}. Since then, it has been widely used in practice. For example, Google Search has adopted this method in October 2019 (REFERENCE). To the best of our knowledge, there is no other paper in operations management literature that considers this word embedding technique. We will provide more details about this technique toward the end of this section.

We apply the following steps to measure the text-based dispersion. First, we use the BERT model to convert every piece of review text to a numerical vector. Second, we normalize each vector to unit length. Third, we measure the cosine similarity to find the similarity between every two review vectors. We note that normalization and the cosine similarity measure are standard to identify the similarity between two vectors. See, e.g., \cite{hoberg2016text}. The cosine similarity between two normalized vectors $V_{1}$ and $V_{2}$ equals the inner product of two, i.e.,$V_1 \cdot V_2$, and gives the cosine of the angle between the two vectors. This angle represents the similarity in the orientation of two vectors. If the angle is $0$, the two vectors are at the same orientation and hence the similarity is $1$, which is maximum. After this step, we identify the cosine distance between every two review vectors from the fact that the cosine distance between two normalized vectors $V_{1}$ and $V_{2}$ equals $1$ minus the cosine similarity between the two. This distance reflects how different two reviews are from each other. As the final step, we calculate the dispersion in sets of text reviews, \emph{text-based dispersion}, in short, by enumerating all pairwise distances of reviews in that set and taking their statistical median (the 50th percentile). For example, for a set of 10 text reviews, we have 45 (=$\binom{10}{2}$) pairwise distances. Finding the text-based dispersion for this set requires computing the median distances of these 45 distances. If these 10 pieces of texts are dissimilar from each other, they contain richer information and the median of these $45$ distances shall be higher; and vice versa.

As a result of this procedure, similar to the ratings entropy, we create the following three variables, each measuring the text-based dispersion in a different dimension: (i)$\text{Text-Dispersion\_Self}$$_{i,t}$: Dispersion in installer $i$'s own text reviews up to month $t$. %Given $N_{i,t}$ pieces of text reviews available up to month $t$, it is calculated by computing $N_{i,t}\times (N_{i,t}-1)/2$ cosine distance pairs and taking the 50$^{th}$ percentile.
(ii) $\text{Text-Dispersion\_Others}$$_{i,t}$: Dispersion in the text reviews of all other installers in the installer $i$'s local market up to month $t$. %Given $N_{-i,t}$ pieces of text reviews of other installers up to month $t$, it is calculated by computing $N_{-i,t}\times (N_{-i,t}-1)/2$ cosine distance pairs and taking the 50$^{th}$ percentile.
(iii)$\text{Text-Dispersion\_Mkt}$$_{m,t}$: Dispersion in text reviews of all installers in market $m$ up to month $t$. %Given $N_{m,t}$ reviews available in market $m$ up to month $t$, we calculate $N_{m,t}\times (N_{m,t}-1)/2$ cosine distance pairs and take the 50$^{th}$ percentile to calculate the variable.


We now elaborate the BERT model we used to \textit{vectorize} the text reviews. BERT is a natural language processing (NLP) model that transforms texts into numeric vectors while also preserving the meaning of texts. It belongs to the category of NLP methods called word embedding. In literature, in different contexts than ours, text data are commonly vectorized based on word counts, ignoring the semantics and word ordering (See, e.g., \cite{hoberg2016text} and \cite{loughran2011liability}). However, our context involves texts that are informal writings and often contain emotions. Simply capturing word frequencies does not provide accurate results if similar emotions can be expressed with synonymous words.  Thus, our analysis requires a vectorization that preserves the information and sentiment of the text reviews despite the use of synonyms and/or different styles. The BERT model achieves that. Specifically, the BERT model has two distinct advantages. First, it understands the semantics. For example, consider the 3 sentences:
\begin{align*}
{\footnotesize
\text{Sentence 1: \texttt{they did a good job.}} \quad \text{Sentence 2: \texttt{they did an awful job.}} \quad \text{Sentence 3: \texttt{they did a great job.}}
}
\end{align*}
Considering the meaning of the sentences, we expect the distance between sentences 1 and 3, $D(1,3)$, to be smaller than the distance between 2 and 3 or 1 and 2, i.e., $D(2,3)$ or $D(1,2)$. The BERT model vectorization enables just that; it projects ``good'' and ``great'' to vectors that are closer to each other. In this example, with BERT, we have $D(1,3) = 0.03 < D(1,2) = 0.09 <D(2,3) = 0.1$. This level of distinction is not feasible without word embedding (e.g., by simply using a word counter vectorizer).

Second, the BERT model takes word ordering into account. For example, the two sentences ``The food was good, not bad at all'' and ``The food was bad, not good at all'' have the opposite meaning. Common vectorization methods (e.g., ``bag-of-words'' approach) are not able to capture this difference as words and number of counts are the same in both sentences. But, the BERT model can easily differentiate between these two sentences.


\section{Installer-Level Empirical Analysis \& Results}

This section answers the following two questions: (i) How does the dispersion in an installer's reviews impact the  number of proposals generated by the installer, which is referred to as the installer's \emph{activity level}. (ii) How does the dispersion in competitor installers' reviews impact the installer's activity level?

To answer these questions, we run a regression model where the response variable is $\text{Installer\_Activity}_{i,m,t}$ and calculated as $\log$(proposals generated by installer $i$ + 1) in the market $m$ during month $t$. In our regression, first, we only use numerical ratings. Later, as a separate analysis, we will use text-based dispersion variables in our regression.

\subsection{Ratings-based Model \& Controls}

Recalling the entropy variables defined in Section \ref{Subsec: Define Ent}, we run the following regression model on our panel data:
\begin{align}  \nonumber
    \text{Installer\_Activity}_{i,m,t+1} =&\beta_{0}+\beta_{1} \text{Entropy\_Self}_{i,t}+\beta_{2} \text{Entropy\_Self}_{i,t}^ {2}+\beta_{3} \text{Entropy\_Others}_{i,t} \\ \label{model_ind_3}
    &\hspace{5pt}+\beta_{4}\text{Entropy\_Others}_{i,t}^{2} + \text{Controls}_{i,m,t}+ \alpha_{i} + \epsilon_{i,t+1}.
\end{align}
 Here, $\epsilon$ is the installer-level error term, and represents random factors that are unobservable in the data and affect the installer activity.


 We run two versions of \eqref{model_ind_3}: In one version, we consider $\alpha_{i}$ as a fixed effect whereas in the alternative version, we consider it as a random effect. To determine which model is more appropriate for our data, we run the Durbin-Wu-Hausman test where the null hypothesis is that the the random-effect model is preferred while the alternative is the fixed-effect model. With a p-value $<0.0001$, we reject the null hypothesis and conclude that the fixed-effect model is more appropriate. We also establish the significance of the fixed effect in \eqref{model_ind_3} with the $F$-test. Thus, we focus on \eqref{model_ind_3} with the installer-level fixed effect $\alpha_{i}$ that controls for time-invariant characteristics of each installer.


 The regression \eqref{model_ind_3} includes various additional installer-level or market-level control variables ($\text{Controls}_{i,m,t}$). To account for the state-level renewable policy effects, we include state dummies denoted by ``State'' as a control variable. We have 33 such variables. We account for the impact of the solar panel prices on installers' activities by considering $\text{Price\_Difference}_{i,t}$ as another control variable. We use the TTS data to find each installer's price for 1 KW solar panel via matching name and zipcode. In practice, price per KW is a common way to assess the price of a solar panel as solar systems vary in size. Based on this, we compute the variable $\text{Price\_Difference}_{i,t}$ as taking the logarithm of the difference between installer $i$'s price and the average price of its competitors that operate in the same market in month $t$ \textbf{IS THIS CALCULATED FOR EACH MONTH?}.
 We control for the self average rating of each installer $i$ $\text{Avg\_Rating\_Self}_{i,t}$  as well as the average ratings of its competitors $\text{Avg\_Rating\_Others}_{i,t}$ in the market for month $t$. We also control for the experience of the installer by considering the variable $\text{Experience}_{i,t}$ that is the logarithm of number of years the installer has been installing solar systems up to month $t$. We obtain this information from each installer's website. Another control variable in \eqref{model_ind_3} is $\text{Market\_Revenue}_{m,t}$  that measures the total dollar value of all solar installations within market $m$ during month $t$. To create this variable, we augment the market boundaries identified in Section \ref{defining_local_market} with the TTS data to capture total  solar installations opportunities in the market. Finally, we consider the count of each installer $i$'s self reviews up to (and including) month $t$, and denote it by $Review\_Counts_{i,t}$.

 \textbf{PLEASE VERIFY THE DEFINITION OF \text{Total\_Installations}}.


\textbf{YOU MENTIONED controls are to capture factors that are irrelevant to the rating entropy. Is Experience really irrelevant to the rating entropy??}



% the following regression equation is used to estimate the impact of ratings dispersion (own ratings dispersion: $Ent_{i,self,t}$ ; others ratings dispersion: $Ent_{i,others,t}$) on focal installer's activity intensities $ActInt_{i,m,t}$:
%\begin{equation}
%    ActInt_{i,m,t+1}=\beta_{0}+\beta_{11} Ent_{i,m,others,t}+\beta_{2}Ent_{i,m,others,t}^2+
%   Controls_{i,t}+\alpha_{i}+\epsilon_{i,m,t}
%   \label{model_ind_1}
%\end{equation}
%
%\begin{equation}
%    ActInt_{i,m,t+1}=\beta_{3}+\beta_{4} Ent_{i,self,t}+\beta_{5}Ent_{i,self,t}^2+
%   Controls_{it}+\alpha_{i}+\epsilon_{i,m,t}
%   \label{model_ind_2}
%\end{equation}

Tables \ref{sumstats_ind} and \ref{corr_ind} below present the summary statistics and the correlation matrix. By Table \ref{corr_ind}, correlations are in the expected direction and do not hurt the validity of regression analysis.
\textbf{PLEASE UPDATE VARIABLE NAMES AND TABLE 3}
\input{summarystats_ind_dec17.tex}

\input{corr_individual_jan30.tex}

\subsection{Ratings-based Results}

Table \ref{reg_ind_all} presents results estimated by three panel regression models based on \eqref{model_ind_3}. Columns (1) through (3) of Table \ref{reg_ind_all} correspond to results obtained by using different set of explanatory variables in the regression. The results in the column (3) correspond to the ones estimated by \eqref{model_ind_3}; others are estimated by considering only some of these variables in the regression.


\input{reg_ind_all.tex}

Our estimates in Table \ref{reg_ind_all} identify three key results. First, the set of variables representing ``noise'' or dispersion of ratings have a significant impact on the activity level of an installer in the marketplace. Second, the entropy of an installer's own ratings has a positive and statistically significant effect on its activity level (because $\beta_{1}$ in equation \eqref{model_ind_3} is found to be positive and significant in column(3) of Table \ref{reg_ind_all}), and the second-order effect ($\beta_{2}$ in equation \eqref{model_ind_3})) of an installer's ratings entropy is negative and statistically significant. Combining these two effects, the regression estimates indicate that the dispersion of an installer's own ratings increases the installer's activity level if and only if the aforementioned dispersion is small. When the dispersion of its own ratings is large, any additional dispersion in the installer's own ratings deters the its activity in the marketplace.

Third and most important, our estimation shows that the entropy of competitor ratings impacts an installer's activity level in the \emph{same} way as the entropy of the installer's own ratings. That is, the dispersion of competitor ratings increases the installer's activity level if and only if the aforementioned dispersion is small. When the dispersion of competitor ratings is large, any additional dispersion in competitor ratings deters the installer's activity in the marketplace.

Figures \ref{fig: marginsplot_ind_ent_self} and  \ref{fig: marginsplot_ind_ent_others} illustrate the explained non-linear effects of the rating entropy on installer's activity level. To generate the marginal effects displayed in Figures \ref{fig: marginsplot_ind_ent_self} and  \ref{fig: marginsplot_ind_ent_others}, we use the estimated regression coefficients from the column (3) of Table \ref{reg_ind_all}. As is apparent from these figures, the installer's activity level first increases then decreases with the rating dispersion, and that is true both when own ratings and its com, regardless of them being based on own ratings or its competitors' ratings.

\begin{figure}
	\centering
	\includegraphics[width=0.7\linewidth]{marginsplot_entothers.png}
	\caption{Marginal Impact of the Entropy of Other Installers' Ratings (in the same market) on the Installer's Activity Level}
	\label{fig: marginsplot_ind_ent_others}
\end{figure}



\begin{figure}
	\centering
	\includegraphics[width=0.7\linewidth]{marginsplot_entself.png}
	\caption{Marginal Impact of the Entropy of the Installer's Own Ratings on its Activity Level}
	\label{fig: marginsplot_ind_ent_self}
\end{figure}









\section{Market-Level Analysis}





We next perform the analysis on a market level. We analyze the connection between market level ratings dispersion and the market level outcomes.  We use a regression model with fixed effects and clustered standard errors on the local market level. \\
To measure the success of the market, we use the total number of accepted quotes. There are several reasons that we use accepted quotes as the performance metrics: 1. The goal of the market place is to help customers connect with installers. 2. The market itself, just like many other market place, is also evaluated by the transaction volume in a business sense. \\
We create the dependent variable of interests using the following data transformation. For every local market $m$, we sum up the total number of quotes accepted per that month ($QuotesWon_{imt}$) for every installers $i$ on that market, and take the log transform.
\begin{align*}
SumQuotes_{m,t}=\sum_{i\in m} QuotesWon_{i,m,t}\\
MarketActivity_{m,t}=\log (SumQuotes_{m,t}+1)
\end{align*}
By doing that, we convert the installer-monthly level panel data from previous section to a market-monthly level panel data so that we can exploit the variations on market level reviews dispersion to identify their impact on local market outcomes.  \\
Using the indexes $m$ for local market, $t$ for month, the following regression equation is used to estimate the impact of ratings dispersion on the local market on the local market performance metrics.
\begin{equation}
    MarketActivity_{m,t+1}=\beta Ent_{m,t}+\beta Ent_{m,t}^2+Controls+\epsilon_{mt}
\end{equation}

Where $MarketActivity_{m,t+1}$ indicate the log of the total number of proposals accepted on market $m$ in month $t+1$, and the model link it to the $Ent_{i,m,t}$ - Entropy of reviews from all installers on that local market.


\subsubsection{Control Variables}\hfill\\
We use the following control variables for the market level analysis\\
\textbf{State}. There are 33 different state represented in the data set, so we created 33 state dummies. Some market span across more than one state. In that case, we weighted state dummy with the percentage. \\
\textbf{Experience}: similar to individual level experience. We created $AvgExp_{m,t}$ variable to represent the average experience of installers on the local market. \\
\textbf{Average Ratings}: similar to individual level analysis, we use the $AvgRating_{m,t}$ to control for the average rating of installers on the local market. A higher $AvgRating$ may improve give the local market a boost across the board.
\textbf{Market condition}:
Similar to individual analysis, we use the total monthly revenues from that market to control for market conditions.
\textbf{Price}: Follow the individual analysis, we look at the difference of average unit price between marketplace and off-marketplace. We use $PriceDiff_{m,t}$ to denote this variable.  \\
\begin{align*}
\log ZipRev_{m,t}=\log \sum_{j\in m}Rev_{j,t}
\end{align*}
 \textbf{The total number of reviews on the market } We use
\begin{align*}
SumReviews_{m,t}=\sum_{i\in m} Reviews_{i,m,t}
\end{align*}

\input{reg_mkt_0.tex}

\input{reg_mkt_1.tex}

\begin{figure}
	\centering
	\includegraphics[width=0.7\linewidth]{marginsplot_mkt_0.png}
	\caption{Marginal Impact of Average Ratings on Market Level Matching}
	\label{marginsplot_mkt_0}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[width=0.7\linewidth]{marginsplot_entmkt.png}
	\caption{Marginal Impact of Market Reviews Entropy of Reviews on Market Level Matching}
	\label{marginsplot_mkt_entmkt}
\end{figure}

We now move to discuss the ratings dispersion on total transactions on local market level. The results are presented in table \ref{reg_mkt_1}. Column (1) and column (2) used fixed effect and random effect, respectively.
\paragraph{Signal}:The results on the local market level also suggest that after controlling for local market conditions, installer experience, price, the `signal' portion of the ratings are not significantly associated with the market level performance.
\paragraph{Noise}: The `noise' portion of the ratings remains a significant factor. The estimate suggest that on the market level reviews dispersion is directly linked to higher number of total proposals accepted, as reflected in the coefficient estimates being positive and statistically significant. We also note that the second order effect is negative as the coefficient estimates associated with the square term is negative and statistically significant. We further illustrate this point with a margins plot using coefficients generated from estimates in column X in figure \ref{marginsplot_mkt_entmkt}. \\
The relationship we found in this section is similar to what we presented earlier. The important distinction is that we are looking at local market at an entire performance unit and measuring the dispersion of ratings on the market level.





\section{Text Mining}
In this section, we incorporate various methods to leverage the rich text information in reviews.  We first use NLP method to generate sentiment score of each reviews. We also apply BERT model to perform word embedding, and generated measures for texts dispersion. We replace quantitative metrics derived from ratings with text mining measures in our analysis.

\subsection{Sentiment Score of reviews Texts}
In this section, we introduce methods to generate sentiment scores on the reviews texts. We use VADER model to generate text sentiment score. VADER, is A Parsimonious Rule-Based Model for Sentiment Analysis of Social Media Text \citep{hutto2014vader}. Since reviews texts shares many stylistic similarities with social media text, this is an appropriate approach. For a piece of text, the language model produces a compound sentiment score from -1 to 1, with 1 representing very positive and -1  very negative sentiments.




 Example 1:
 \begin{displayquote}
Mike at (...) was friendly, courteous, professional and very helpful.  At first I did not know what kind of system I wanted, because my roof was too small and I had some trees in the way.  Mike had never installed a tracking system but he did recommend it.  It seemed like we would get the best "bang for the buck" with this system, so I went with it.  Mike had all subcontractor there on time as well as all the equipment.  It was up and running in less than a week.  I love it.
\end{displayquote}
The above review received a compound sentiment score of 0.8622 and a five-star rating. \\
 Example 2:
\begin{displayquote}
Do not hire (...)  to install a solar system. Do not hire (...) to do anything. Evan   and all his various companies and names  ARE NOT LICENCED OR INSURED. I was scammed by Mr. Evan (...) in December of 2013. He installed the system wrong and incomplete even though all the parts and materials were provided for him. Please take the time to do your research and check references and validate licenses and insurance information. It will save u more money than to trust a cheap con artist. All the info at (...)  is fraudulent lies. Evan Esposito is also known as (...).
\end{displayquote}
This received -0.7184 and an one-star rating.

We apply this method to assign a sentiment score for every piece of reviews texts. Overall, the sentiment score correlates with ratings signficantly($corr = 0.8239$). It is further illustrated in figure \ref{sent_score_scatter} where the scatterplot of all reviews' sentiment scores and ratings is presented.  Follow the same process as discussed in earlier section, we construct variables $AvgSent_{i,t}$ in place of $Avg_{i,t}$, $AvgSentOthers_{i,m,t}$ in place of $AvgOthers_{i,m,t}$ to represent individual ratings in individual level analysis, $AvgSentMkt_{m,t}$ in place of $AvgMkt_{m,t}$ in market level analysis.
\begin{figure}
	\centering
	\includegraphics[width=0.7\linewidth]{sent_score_scatter.png}
	\caption{Sentiment Scores and Ratings}
	\label{sent_score_scatter}
\end{figure}

\subsection{Analysis using Variables Derived From Text Mining}


We replaced average rating with average sentiment scores and replace ratings entropy with text-based dispersion and re-run both individual and market level analysis. The results are presented in table \ref{reg_ind_3} and table \ref{reg_ind_4} . Likewise we run the same regression on the market level data and presented the results in table \ref{reg_mkt_2}. We observe the same type of inverse U shape for the marginal impact of text-based dispersion. This result comes at no surprise as the two measures of ratings dispersion are correlated significantly, although the magnitude of correlation isn't very high ().  We found that the even after we include both  \\





\section{Robustness Check}
\subsection{Endogeneity}

We devised several empirical strategies to mitigate the potential drawbacks of endogeneity or omitted variables in our analysis. Regarding the individual level analysis, endogeneity could occur if there are unobserved factors that is significantly correlated with ratings dispersion that is also correlated with the activity intensities.\\
Consider that we omitted a variable that captures installer professionalism or motivation, which we denote as $pro_{i,t}$. The actual function should be
\begin{equation}
ActInt_{i,m,t+1}=\delta pro_{i,t}+\beta_{1} Ent_{i,m,others,t}+\beta_{2}Ent_{i,m,others,t}^2+controls+\epsilon_{i,m,t}
\end{equation}
We argue that $pro_{it}$ would be \textit{negatively} correlated with reviews dispersion -- professional installers would be more motivated than others to deliver consistent products and services (CITE some thing).  \\

In this case, the presence of omitted variable deflated the estimates of $\beta$ (CITE ECONOMETRIC stuff). \\


\subsection{Robustness with different local market division}
Although many similar studies used ZIP code to difine local markets(cite something from IO), we used unsupervised algorithm (OPTICS) to determine the market grouping. OPTICS algorithm requires a few parameter inputs: X, Y and Z. We used parameter XX after performing grid-search on a parameter space XXX and use Calinski-Harabasz Index to assess the appropriateness of the clustering.  \\ In addition, we used 4 digit ZIP code to define a market and the results are consistent ( INSERT RESULTS); we also use other OPTICS parameter and the results are consistent.  \\

\subsection{Dynamic Panel model}
In our main analysis we include both fixed effect for each installer to account for time invariant factors. We use a dynamic panel model to perform robustness check. The inclusion of lagged dependent variable ( Activity Intensity) aim to control for unobserved heterogeneity that may influence changes in the dependent variable and is time variant. For individual level estimation, the equation we estimate is changed into the following:
\begin{equation}
    ActInt_{i,m,t+1}=\gamma ActInt_{i,m,t-1}+Ent_{i,m,others,t}+Ent_{i,m,others,t}^2+
    controls+\epsilon_{i,m,t}
\end{equation}

\begin{equation}
    ActInt_{im,t+1}=\gamma Ent_{im,t-1}+\beta_{3}+\beta_{4} Ent_{i,self,t}+\beta_{5}Ent_{i,self,t}^2+
   Controls+\epsilon_{imt}
   \label{model_ind_dyn_1}
\end{equation}

\begin{equation}
    ActInt_{im,t+1}=\gamma Ent_{im,t-1}+\beta_{6}+\beta_{7} Ent_{i,self,t}+\beta_{8}Ent_{i,self,t}^2+\beta_{9}Ent_{im,others}+\beta_{10}Ent_{im,self,t}^2+
   Controls+\epsilon_{imt}
   \label{model_ind_dyn_2}
\end{equation}
We expect $\gamma$ estimates to be positive. The results are still consistent as the $\beta$ coefficients associated with $Ent_{others}$($Ent_{others}^2$) are still positive (negative) as presented in table \ref{rob_addlag} and \ref{rob_addlag_withentself}.

Likewise, we modify the market level model to include a lagged dependent variable $MarketActivity_{m,t-1})$
\begin{equation}
    MarketActivity_{m,t+1}=\gamma MarketActivity_{m,t-1}+\beta Ent_{m,t}+\beta Ent_{m,t}^2+Controls+\epsilon_{mt}
\end{equation}
and the results, presented in table \ref{rob_addlag_mkt}, are still consistent.
\input{rob_installer_regression_dec25.tex}
\input{rob_installer_regression_addlag_withentself.tex}
\input{rob_mkt_regression_dec25.tex}

\subsection{Market Level Alternative Measure of Success}
\input{reg_mkt_3.tex}
In the analysis of ratings dispersion on local market level performance, we used total quotes accepted by consumers to measure the success of marketplace. We present results using total quotes given out by installers, and it remains consistent, as table \ref{reg_mkt_3} shows.

\subsection{Text-based Dispersion measure}
\input{reg_ind_42.tex}
We used median of cosine distances for measure of dispersion. The mean of cosine distances are consistent, per table \ref{reg_ind_42}.
\subsection{Excluding Inactive Installers}
Although we do not explicitly model the process of installers exiting platform, we are aware of its potential to drive results. We ran a robustness check excluding installers that have been inactive for two month ( making 0 proposals), with results presented in table \ref{rob_exclude_inactive}. The first two columns are results excluding these said installers ( cluster standard errors on market level - column (1); individual level - column (2)) . The results are virtually unchanged, especially on the independent variable of interests.
\input{rob_excludeinactive_jan7.tex}

\section{Discussions}
The impact of signal and noise in performance reviews on action-takers are perplexing. Prior literature ...signal... , the collective role of signal and noise have not been empirically investigated. Our study makes several important contributions:
\paragraph{Average (Signal)} : Most the specifications concerning the impact of average ratings captured negative (yet statistically insignificant) effects.   Interestingly, the model using sentiment score and Text-based dispersion measures (table \ref{reg_ind_3} and \ref{reg_ind_4} have shown more consistent and significant negative coefficients. After we control for other things, being rated higher or viewed more positive is associated with a lower level of activity intensity going forward. \\



\paragraph{EntOthers (Noise)} The individual level analysis pertain to $EntOthers$ covariates all revealed an inverse-U shape impact.
\paragraph{EntSelf (Noise)}

\paragraph{Market Level Impact}

\paragraph{Methodology - text mining} To analyze the reviews texts, we incorporated two text mining methods that 1) - gave reviews texts a one-dimensional sentiment score and 2) utilize word embedding model to measure texts similarity with precision. We demonstrated that the text mining tools are great complement to the quantitative data. To our knowledge, it is the first example of using deep learning based text-mining models on business settings in the operations literature. We demonstrate the versatility of word-embedding methods as a complement to traditional text-mining methods.
\begin{APPENDIX}{Note and Questions for Our Own References }

\section{Tests for Fixed and Random Effects in \eqref{model_ind_3}}\ref{Apx: Hausman}

\textbf{PLEASE INSERT A TABLE THAT REPORTS THE TEST RESULTS}



\section{My Earlier Question}

What is the total number of proposals in each year?
Which state is number \#1 in terms of total wins/total proposals?
Which state is worst in terms of total wins/total proposals?
Q1) IF THEY OPERATE AT MULTIPLE LOCATIONS, DO THEY PROVIDE
THAT INFO ON THEIR PROFILE? \\
We do not have info if they operated on multiple locations or not. I scrape their headquarter address , with ZIP code info.
Q2) WHAT IS THE FORMAT OF THE LOCATION INFO - IS IT A DETAILED
ONE WITH A ZIPCODE? PLEASE INCLUDE AN EXAMPLE FOR ME HERE. \\
Emerald Energy of North Carolina Headquarters
2624 Leighton Ridge Drive, Suite 120
Wake Forest, NC
27587 US

COULD YOU PLEASE PREPARE THESE TWO GRAPHS? 1) TOTAL NUMBER
OF REVIEWS PER INSTALLER - MAX NUMBER OF REVIEW FOR AN IN-
STALLER AND HISTOGRAM? 2) NUMBER OF INSTALLERS IN EACH STATE
FOR TOP 10 STATES \\
QUESTIONS: 1) HOW MANY OF THE INSTALLERS DO NOT HAVE A RE-
VIEW? 2) WHAT IS THE PERCENTAGE OF THOSE INSTALLERS IN THE LO-
CAL MARKET WIN AND SUBMITTED PROPOSALS? 3) WHAT DO YOU AS-
SUME ABOUT THEM IN THE EMPIRICAL ANALYSIS? \\
We didn't need to assume anything. I just computed all the variables the way as we stated. \\
All installers started with 0 reviews, naturally. \\
If we look at the observations that are included in the analysis, less than 5 percent of observations have 0 reviews ( mostly due to its newly established). \\
If we look at the end of the panel, only 1 installer has 0 reviews, and have a positive entothers value ( hence is included in the analysis)

\end{APPENDIX}


\clearpage
% Appendix here
% Options are (1) APPENDIX (with or without general title) or
%             (2) APPENDICES (if it has more than one unrelated sections)
% Outcomment the appropriate case if necessary
%
% \begin{APPENDIX}{<Title of the Appendix>}
% \end{APPENDIX}
%
%   or
%
% \begin{APPENDICES}
% \section{<Title of Section A>}
% \section{<Title of Section B>}
% etc
% \end{APPENDICES}


% Acknowledgments here
\ACKNOWLEDGMENT{ .}


% References here (outcomment the appropriate case)

% CASE 1: BiBTeX used to constantly update the references
%   (while the paper is being written).
%\bibliographystyle{informs2014} % outcomment this and next line in Case 1
%\bibliography{<your bib file(s)>} % if more than one, comma separated

% CASE 2: BiBTeX used to generate mypaper.bbl (to be further fine tuned)
%\input{mypaper.bbl} % outcomment this line in Case 2

%If you don't use BiBTex, you can manually itemize references as shown below.


\bibliographystyle{informs2014} % outcomment this and next line in Case 1
\bibliography{solarlits} % if more than one, comma separated


%%%%%%%%%%%%%%%%%
\end{document}
%%%%%%%%%%%%%%%%%

